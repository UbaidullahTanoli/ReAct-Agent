{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UbaidullahTanoli/ReAct-Agent/blob/main/LLM_ReAct_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1.   Install Packages**\n",
        "\n",
        "**2.   Import Libraries**\n",
        "\n",
        "**3.   Setting API Keys**\n",
        "\n",
        "**4.   Instantiate LLM**\n",
        "\n",
        "**5.   Prompt**\n",
        "\n",
        "**6.   Load Tools**\n",
        "\n",
        "**7.   Create Agent**\n",
        "\n",
        "**8.   Store Chat History**\n",
        "\n",
        "**9.   Prompt and Invoke**\n"
      ],
      "metadata": {
        "id": "FsOlKAxq1IRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u3qDiAdu29lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Install Packages**"
      ],
      "metadata": {
        "id": "7D8vehZC3AOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the neccessary packages\n",
        "\n",
        "!pip install transformers\n",
        "!pip install intel-extension-for-transformers\n",
        "!pip install langchain-huggingface text-generation google-search-results numexpr langchainhub sentencepiece jinja2\n",
        "!pip install datasets\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install peft\n",
        "!pip install accelerate\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install google-search-results\n",
        "!pip install to-requirements.txt\n",
        "!pip freeze > requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "!pip install neural-speed\n",
        "!git clone https://github.com/intel/neural-speed.git;\n",
        "!git clone https://github.com/intel/intel-extension-for-transformers.git itrex\n",
        "!python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!python -m pip install intel-extension-for-pytorch\n",
        "!python -m pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
        "!python -m pip install torch==2.1.0.post0 torchvision==0.16.0.post0 torchaudio==2.1.0.post0 intel-extension-for-pytorch==2.1.20+xpu oneccl_bind_pt==2.1.200+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n",
        "!pip install --upgrade torch functorch\n",
        "!pip install --upgrade protobuf\n",
        "!pip install langchain_cohere"
      ],
      "metadata": {
        "id": "vpgJEmbJ1DYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Import Libraries**"
      ],
      "metadata": {
        "id": "ivXofUtM3Er0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1w7uIHc9Q6V"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "\n",
        "import accelerate\n",
        "import torch\n",
        "import os\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain import hub\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.agents import AgentExecutor, load_tools\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents.output_parsers import (ReActJsonSingleInputOutputParser)\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdbYhaCemXhA",
        "outputId": "fc24b69c-14c2-4398-863a-4b78f702b447",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/neural-speed\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/')\n",
        "\n",
        "os.chdir('/content/')\n",
        "!pwd\n",
        "\n",
        "os.chdir('/content/neural-speed/')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Setting API Keys**"
      ],
      "metadata": {
        "id": "HM74t6ai3MWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C03PV1IhZ7SJ"
      },
      "outputs": [],
      "source": [
        "# Setting the Hugging Face API key as an environment variable\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "# Setting the SerpAPI key as an environment variable\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"598c99d847d8b4fbe441722ac89fdc2089ea90154f53dc34c4cc8d1ac171f7e8\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Instantiate LLM**"
      ],
      "metadata": {
        "id": "qQF1784O3dTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "flB2n-tqMe5N"
      },
      "outputs": [],
      "source": [
        "# Instantiate llm\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"google/gemma-7b\",\n",
        "    model_kwargs={\"temperature\":1, \"max_length\":250, 'max_new_tokens': 200, 'top_k': 10, 'top_p': 0.95, 'repetition_penalty':1},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Prompt**"
      ],
      "metadata": {
        "id": "KnntRf5p3kXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What constitutes an atom?\"\n",
        "context = \"Classical vs quantum limit\"\n",
        "\n",
        "template = \"\"\"If the context is not relevant,\n",
        "        please answer the question by using your own knowledge about the topic\n",
        "\n",
        "        {context}\n",
        "\n",
        "        Question: {question}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "            template=template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "#prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "chain.invoke({\"context\": context, \"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "nZdXVCi1zqAU",
        "outputId": "dfb93c10-66e2-4c65-ecf4-dbab7cd31eb7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"If the context is not relevant,\\n        please answer the question by using your own knowledge about the topic\\n\\n        Classical vs quantum limit\\n\\n        Question: What constitutes an atom?\\n\\n        Answer: An atom is a collection of protons, neutrons and electrons.\\n\\n        Question: What is a classical description?\\n\\n        Answer: A classical description is a description of the atom\\n              that is based on Newton's law, i.e. it is based on\\n              a continuum description and ignores the quantum nature\\n              of the system.\\n\\n        Question: What is a quantum description?\\n\\n        Answer: A quantum description is a description of the atom\\n              that is based on the Schr√∂dinger equation and takes\\n              into account the quantum nature of the system (i.e. it\\n              is based on a discrete approach rather than a continuous\\n              one).\\n\\n        Question: Why do we need a quantum description of the atom?\\n                  What is the problem with the classical description?\\n\\n        Answer: Because the classical description does not\\n              take into account the discrete nature of the atom.\\n              This is because the classical description is based\\n              \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Load Tools**"
      ],
      "metadata": {
        "id": "7MHWmtFY3sKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "4XqN-EYBki4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Create Agent**"
      ],
      "metadata": {
        "id": "3ZT0TH4J32Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = ChatPromptTemplate.from_messages(\n",
        "#    [\n",
        "#        (\n",
        "#            \"system\",\n",
        "#            \"You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.\",\n",
        "#        ),\n",
        "#        (\"placeholder\", \"{chat_history}\"),\n",
        "#        (\"human\", \"{input}\"),\n",
        "#        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "#    ]\n",
        "#)\n",
        "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
        "# Construct the Tools agent\n",
        "#agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "agent = create_structured_chat_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "avpj_DypkWS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "ejGWSEx260Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "IhvpCmCZ608i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=10,\n",
        ")"
      ],
      "metadata": {
        "id": "psTIk0QykWVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Store Chat History**"
      ],
      "metadata": {
        "id": "3-my1odP4D9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
        "agent_executor.invoke({\"input\": \"Hi! my name is Sab\", \"chat_history\": []})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG298hLakWaP",
        "outputId": "606a0b82-6732-481a-cc1c-3dc580b1e9d6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Hi! my name is Sab',\n",
              " 'chat_history': [],\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = ChatMessageHistory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "N-BG7fkTkWc6",
        "outputId": "19fe5682-f3dd-4fa7-bc15-9c13380bd12f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ChatMessageHistory' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-007b62463c0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmessage_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatMessageHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ChatMessageHistory' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    lambda session_id: message_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "InA6GvFgkWe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"Hi! I'm Sab\"},\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sqop5Of9kWiQ",
        "outputId": "af6165be-5a14-41ec-d69d-b3dc19bba22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"Hi! I'm Sab\",\n",
              " 'chat_history': [],\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Prompt and Invoke**"
      ],
      "metadata": {
        "id": "UvWMCoP34MHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Construct the Tools agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "GRI3IWn0197Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e5bc42e2-da20-48e4-9d6a-1b15aeaeeb4e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "This function requires a .bind_tools method be implemented on the LLM.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fa82265496c7>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Construct the Tools agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/tool_calling_agent/base.py\u001b[0m in \u001b[0;36mcreate_tool_calling_agent\u001b[0;34m(llm, tools, prompt, message_formatter)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bind_tools\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;34m\"This function requires a .bind_tools method be implemented on the LLM.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: This function requires a .bind_tools method be implemented on the LLM."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}